{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0104b088",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def find_best(X, y, c):\n",
    "#     smallest_error = np.Inf\n",
    "#     best_index = -1\n",
    "#     error = 0.0\n",
    "#     ls = []\n",
    "#     for coeff in c:\n",
    "#         for xi,yi in zip(X,y):\n",
    "#             error = error + ((xi @ coeff) - yi)**2\n",
    "#         ls.append(error)\n",
    "#     print(ls)\n",
    "#     best_index = ls.index(min(ls))\n",
    "#     print(best_index)\n",
    "        \n",
    "             # edit here: calculate the sum of squared error with coefficient set coeff and\n",
    "                 # keep track of the one yielding the smallest squared error\n",
    "#     print(\"the best set is set %d\" % best_index)\n",
    "# max_index = fishers.index(max(fishers))\n",
    "\n",
    "#find_best(X, y, c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "03f4317f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1367335000.0, 144765000.0, 676665000.0]\n",
      "[array([258250,  76100, 492750]), array([254550,  61400, 536050]), array([270250,  70200, 537750])]\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# data\n",
    "X = np.array([[66, 5, 15, 2, 500], \n",
    "              [21, 3, 50, 1, 100], \n",
    "              [120, 15, 5, 2, 1200]])\n",
    "y = np.array([250000, 60000, 525000])\n",
    "\n",
    "# alternative sets of coefficient values\n",
    "c = np.array([[3000, 200 , -50, 5000, 100], \n",
    "              [2000, -250, -100, 150, 250], \n",
    "              [3000, -100, -150, 0, 150]])   \n",
    "\n",
    "def find_best(X, y, c):\n",
    "    smallest_error = np.Inf\n",
    "    best_index = -1\n",
    "    new_y = []\n",
    "    for coeff in c:\n",
    "        new_y.append(X @ coeff)\n",
    "    error = []\n",
    "    for i in range(len(new_y)):\n",
    "        k = 0.0\n",
    "        for m,n in zip(y,new_y[i]):\n",
    "            k = k + (m-n)**2\n",
    "        error.append(k)\n",
    "    print(error)\n",
    "    best_index = error.index(min(error))    \n",
    "        \n",
    "    print(new_y)\n",
    "    print(best_index)\n",
    "#         pass     # edit here: calculate the sum of squared error with coefficient set coeff and\n",
    "#                  # keep track of the one yielding the smallest squared error\n",
    "#     print(\"the best set is set %d\" % best_index)\n",
    "find_best(X,y,c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b080a490",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250000\n",
      "258250\n",
      "60000\n",
      "76100\n",
      "525000\n",
      "492750\n",
      "1367335000.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "X = np.array([[66, 5, 15, 2, 500], \n",
    "              [21, 3, 50, 1, 100], \n",
    "              [120, 15, 5, 2, 1200]])\n",
    "y = np.array([250000, 60000, 525000])\n",
    "c = np.array([3000, 200 , -50, 5000, 100])    # coefficient values\n",
    " \n",
    "\n",
    "sse = 0.0\n",
    "y_new = X @ c\n",
    "for m,n in zip(y,y_new):\n",
    "    sse = sse + (m-n)**2\n",
    "    print(m)\n",
    "    print(n)\n",
    "\n",
    "print(sse)\n",
    "# for xi, yi in zip(X, y):\n",
    "\n",
    "#         # add your code here: calculate the predicted price,\n",
    "#         # subtract it from the actual price yi, \n",
    "#         # square the difference using (yi - prediction)**2, \n",
    "#         # and add up all the differences in variable sse\n",
    "# see = sse = sse + ((xi @ c) - yi)**2\n",
    "\n",
    "# print(sse)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ce954b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "1367335000.0\n",
    "144765000\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "05506362",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  25    2   50    1  500]\n",
      " [  39    3   10    1 1000]\n",
      " [  13    2   13    1 1000]\n",
      " [  82    5   20    2  120]\n",
      " [ 130    6   10    2  600]\n",
      " [ 115    6   10    1  550]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "a = np.array(\n",
    "        [\n",
    "            [25, 2, 50, 1, 500], \n",
    "            [39, 3, 10, 1, 1000], \n",
    "            [13, 2, 13, 1, 1000], \n",
    "            [82, 5, 20, 2, 120], \n",
    "            [130, 6, 10, 2, 600],\n",
    "        ]\n",
    ")\n",
    "\n",
    "b = np.array([\n",
    "    [115,6,10,1,550]\n",
    "]\n",
    ")\n",
    "c = np.concatenate((a,b),axis=0)\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "89341d60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 2]\n",
      " [3 4]\n",
      " [1 2]\n",
      " [3 4]]\n"
     ]
    }
   ],
   "source": [
    "c=np.arange(1,5).reshape(2,2)\n",
    "d = np.concatenate((c,c), axis=0)\n",
    "print(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "178ded91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3000.  200.  -50. 5000.  100.]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from io import StringIO\n",
    "\n",
    "input_string = '''\n",
    "25 2 50 1 500 127900\n",
    "39 3 10 1 1000 222100\n",
    "13 2 13 1 1000 143750\n",
    "82 5 20 2 120 268000\n",
    "130 6 10 2 600 460700\n",
    "115 6 10 1 550 407000\n",
    "'''\n",
    "\n",
    "np.set_printoptions(precision=1)    # this just changes the output settings for easier reading\n",
    "f = StringIO(input_string)\n",
    "a = np.genfromtxt(f,dtype = None)\n",
    "#print(a)\n",
    "n = a.shape[1]\n",
    "#print(n)\n",
    "\n",
    "x = a[:,0:n-1]\n",
    "#print(x)\n",
    "#价格\n",
    "y = a[:,n-1]\n",
    "#print(y)\n",
    "\n",
    "x1 = x[0:5]\n",
    "y1 = y[0:5]\n",
    "c = np.linalg.lstsq(x1, y1 ,rcond=None)[0]\n",
    "print(c)\n",
    "\n",
    "# def fit_model(input_file):\n",
    "#     # Please write your code inside this function\n",
    "\n",
    "#     # read the data in and fit it. the values below are placeholder values\n",
    "#     c = np.asarray([])  # coefficients of the linear regression\n",
    "#     x = np.asarray([])  # input data to the linear regression\n",
    "\n",
    "#     print(c)\n",
    "#     print(x @ c)\n",
    "\n",
    "# # simulate reading a file\n",
    "# input_file = StringIO(input_string)\n",
    "# fit_model(input_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "42f1cbea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  25    2   50    1  500]\n",
      " [  39    3   10    1 1000]\n",
      " [  13    2   13    1 1000]\n",
      " [  82    5   20    2  120]\n",
      " [ 130    6   10    2  600]]\n",
      "[127900 222100 143750 268000 460700]\n",
      "[3000.  200.  -50. 5000.  100.]\n",
      "[127900. 222100. 143750. 268000. 460700. 405700.]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from io import StringIO\n",
    "\n",
    "input_string = '''\n",
    "25 2 50 1 500 127900\n",
    "39 3 10 1 1000 222100\n",
    "13 2 13 1 1000 143750\n",
    "82 5 20 2 120 268000\n",
    "130 6 10 2 600 460700\n",
    "115 6 10 1 550 407000\n",
    "'''\n",
    "\n",
    "np.set_printoptions(precision=1)    # this just changes the output settings for easier reading\n",
    " \n",
    "def fit_model(input_file):\n",
    "    # Please write your code inside this function\n",
    "    a = np.genfromtxt(input_file,dtype = None)\n",
    "    n = a.shape[1]\n",
    "    x = a[:,0:n-1]\n",
    "    y = a[:,n-1]\n",
    "    x1 = x[0:5]\n",
    "    y1 = y[0:5]\n",
    "    print(x1)\n",
    "    print(y1)\n",
    "    c = np.linalg.lstsq(x1, y1 ,rcond=None)[0]\n",
    "    # read the data in and fit it. the values below are placeholder values\n",
    "    # c = np.asarray([])  # coefficients of the linear regression\n",
    "    # x = np.asarray([])  # input data to the linear regression\n",
    "\n",
    "    print(c)\n",
    "    print(x @ c)\n",
    "\n",
    "# simulate reading a file\n",
    "input_file = StringIO(input_string)\n",
    "fit_model(input_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "caf67deb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12.36931687685298\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "print(math.sqrt(153))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "ad642282",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12.36931687685298\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "a = [14, 3, 0.8]\n",
    "b = [2, 6, 0.8]\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def dist(a, b):\n",
    "    sum = 0\n",
    "    for ai, bi in zip(a, b):\n",
    "        sum = sum + (ai - bi)**2\n",
    "    return np.sqrt(sum)\n",
    "\n",
    "print(dist(a,b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "651f85d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training: [[0.8 0.  1. ]\n",
      " [0.6 0.  0.8]\n",
      " [0.2 0.6 0.6]\n",
      " [0.  0.8 0.5]\n",
      " [0.2 0.8 0.9]\n",
      " [0.4 0.5 0.3]\n",
      " [0.8 0.4 0.7]\n",
      " [0.2 0.4 0.6]\n",
      " [0.3 0.2 0.2]\n",
      " [0.4 0.8 0.1]]\n",
      "test: [0.8 0.1 0.4]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "x_train = np.random.rand(10, 3)   # generate 10 random vectors of dimension 3\n",
    "x_test = np.random.rand(3)        # generate one more random vector of the same dimension\n",
    "\n",
    "print(\"training:\",x_train)\n",
    "print(\"test:\",x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "560e0be4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "\n",
    "x_train = np.array([[25, 2, 50, 1, 500], \n",
    "                  [39, 3, 10, 1, 1000],    \n",
    "                  [82, 5, 20, 2, 120], \n",
    "                  [130, 6, 10, 2, 600]])\n",
    "y_train = [127900, 222100,  268000, 460700]\n",
    "\n",
    "x_test = np.array([[115, 6, 10, 1, 560], [13, 2, 13, 1, 1000]])\n",
    "\n",
    "\n",
    "def dist(a, b):\n",
    "    sum = 0\n",
    "    for ai, bi in zip(a, b):\n",
    "        sum = sum + (ai - bi)**2\n",
    "    return np.sqrt(sum)\n",
    "\n",
    "n_train = len(x_train) # number of data points in the training set\n",
    "\n",
    "for test_item in x_test:\n",
    "    d = np.empty(n_train) # d will hold the distances between this test data point and all the training data points\n",
    "    for i, train_item in enumerate(x_train):\n",
    "        d[i] = dist(test_item, train_item)\n",
    "    nearest_index = np.argmin(d) # the nearest neighbour will be in y_train[nearest]\n",
    "    print(y_train[nearest_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97051486",
   "metadata": {},
   "outputs": [],
   "source": [
    "# list方法\n",
    "# array方法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e40aac5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "x_train = np.random.rand(10, 3)   # generate 10 random vectors of dimension 3\n",
    "x_test = np.random.rand(3)        # generate one more random vector of the same dimension\n",
    "\n",
    "def dist(a, b):\n",
    "    sum = 0\n",
    "    for ai, bi in zip(a, b):\n",
    "        sum = sum + (ai - bi)**2\n",
    "    return np.sqrt(sum)\n",
    "    \n",
    "def nearest(x_train, x_test):\n",
    "    nearest = -1\n",
    "    min_distance = np.Inf\n",
    "    distance = []\n",
    "    # add a loop here that goes through all the vectors in x_train and finds the one that\n",
    "    # is nearest to x_test. return the index (between 0, ..., len(x_train)-1) of the nearest\n",
    "    # neighbor\n",
    "    for i in range(len(x_train)):\n",
    "        distance.append(dist(x_train[i],x_test))\n",
    "    nearest = distance.index(min(distance))\n",
    "    print(nearest)\n",
    "\n",
    "nearest(x_train, x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "3f36bfda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "distance:(14x2) [0.9189297873955793, 0.7038105085202159, 0.7362270473393815, 0.6416969851116551, 0.22784894381821477, 0.1563207367984219, 0.08450023025374083, 0.6320719369729264, 0.381815714692994, 0.6864538217699051, 0.5794004540122246, 0.6020309000127991, 0.5464160391582199, 0.09567295306912872]\n",
      "two nearest indext: 6\n",
      "line: [array([[0.8, 0.4],\n",
      "       [0.7, 0.6]]), array([[0. , 1. ],\n",
      "       [0.2, 0.7]]), array([[1. , 0.1],\n",
      "       [0.8, 0.3]]), array([[0.6, 0.9],\n",
      "       [0.5, 0.9]])]\n",
      "[ 0 16]\n",
      "distance:(14x2) [0.864275502428286, 1.0053240810304482, 0.711054858986254, 0.9481429972969802, 0.5913425877001453, 0.8097716416100927, 0.6879933636116209, 0.8001169811069739, 0.5026671080133638, 0.6029503226740084, 0.8700289064577619, 0.4844943810245051, 0.2735770176261715, 0.8019249543710104]\n",
      "two nearest indext: 12\n",
      "line: [array([[0.8, 0.4],\n",
      "       [0.7, 0.6]]), array([[0. , 1. ],\n",
      "       [0.2, 0.7]]), array([[1. , 0.1],\n",
      "       [0.8, 0.3]]), array([[0.6, 0.9],\n",
      "       [0.5, 0.9]]), array([[0. , 0.4],\n",
      "       [0.3, 0.5]])]\n",
      "[0 0]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "# create random data with two classes\n",
    "X, y = make_blobs(n_samples=16, n_features=2, centers=2, center_box=(-2, 2))\n",
    "\n",
    "# scale the data so that all values are between 0.0 and 1.0\n",
    "X = MinMaxScaler().fit_transform(X)\n",
    "\n",
    "# split two data points from the data as test data and\n",
    "# use the remaining n-2 points as the training data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=2)\n",
    "# print(X_train, X_test, y_train, y_test)\n",
    "# place-holder for the predicted classes\n",
    "y_predict = np.empty(len(y_test), dtype=np.int64)\n",
    "# print(y_predict)\n",
    "# produce line segments that connect the test data points\n",
    "# to the nearest neighbors for drawing the chart\n",
    "# lines = []\n",
    "\n",
    "\n",
    "# distance function\n",
    "def dist(a, b):\n",
    "    sum = 0\n",
    "    for ai, bi in zip(a, b):\n",
    "        sum = sum + (ai - bi)**2\n",
    "    return np.sqrt(sum)\n",
    "\n",
    "\n",
    "# def main(X_train, X_test, y_train, y_test):\n",
    "\n",
    "    global y_predict\n",
    "    global lines\n",
    "    \n",
    "    # process each of the test data points\n",
    "for i, test_item in enumerate(X_test):\n",
    "        # calculate the distances to all training points\n",
    "    distances = [dist(train_item, test_item) for train_item in X_train]\n",
    "    print(\"distance:(14x2)\",distances)\n",
    "#         # find the index of the nearest neighbor\n",
    "    nearest = np.argmin(distances)\n",
    "    print(\"two nearest indext:\",nearest)\n",
    "#         # create a line connecting the points for the chart\n",
    "    lines.append(np.stack((test_item, X_train[nearest])))\n",
    "    print(\"line:\",lines)\n",
    "#         # add your code here:\n",
    "    y_predict[i] = distances[nearest]\n",
    "    print(y_predict)\n",
    "    #this just classifies everything as 0 \n",
    "\n",
    "#     print(y_predict)\n",
    "\n",
    "\n",
    "# main(X_train, X_test, y_train, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "258d4125",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1: [[0.  0. ]\n",
      " [0.9 1. ]\n",
      " [0.2 0.2]\n",
      " [1.  0.8]\n",
      " [0.7 0.4]\n",
      " [0.6 0.5]\n",
      " [0.  0.1]\n",
      " [0.2 0.3]\n",
      " [0.7 0.2]\n",
      " [0.4 0.7]\n",
      " [1.  0.7]\n",
      " [0.5 0.7]\n",
      " [0.4 0.7]\n",
      " [0.  0.5]]\n",
      "2: [[0.5 0.4]\n",
      " [0.3 0.1]]\n",
      "3: [1 0 1 0 0 0 1 1 1 0 0 0 1 1]\n",
      "4: [0 1]\n",
      "[0 1]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "# create random data with two classes\n",
    "X, y = make_blobs(n_samples=16, n_features=2, centers=2, center_box=(-2, 2))\n",
    "\n",
    "# scale the data so that all values are between 0.0 and 1.0\n",
    "X = MinMaxScaler().fit_transform(X)\n",
    "\n",
    "# split two data points from the data as test data and\n",
    "# use the remaining n-2 points as the training data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=2)\n",
    "print(\"1:\",X_train)\n",
    "print(\"2:\",X_test) \n",
    "print(\"3:\",y_train) \n",
    "print(\"4:\",y_test)\n",
    "# place-holder for the predicted classes\n",
    "y_predict = np.empty(len(y_test), dtype=np.int64)\n",
    "print(y_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ec942ad0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1]\n",
      "[1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1]\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "data = [[1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1],\n",
    "        [1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1],\n",
    "        [1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1],\n",
    "        [1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1],\n",
    "        [1, 1, 1, 0, 1, 3, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1]]\n",
    "\n",
    "def distance(row1, row2):\n",
    "    total = 0\n",
    "    for i in range(len(row1)):\n",
    "        total = total + abs(row1[i] - row2[i])\n",
    "\n",
    "    # fix this function so that it returns \n",
    "    # the sum of differences between the occurrences\n",
    "    # of each word in row1 and row2.\n",
    "    # you can assume that row1 and row2 are lists with equal length, containing numeric values.\n",
    "    return total\n",
    "\n",
    "row1 = data[1]\n",
    "row2 = data[2]\n",
    "print(row1)\n",
    "print(row2)\n",
    "print(distance(row1,row2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b99ae376",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0  5  6  5 12]\n",
      " [ 5  0  5  4  9]\n",
      " [ 6  5  0  3 12]\n",
      " [ 5  4  3  0 11]\n",
      " [12  9 12 11  0]]\n",
      "(0, 0)\n"
     ]
    }
   ],
   "source": [
    "def all_pairs(data):\n",
    "    # this calls the distance function for all the two-row combinations in the data\n",
    "    # you do not need to change this\n",
    "    dist = np.array([[distance(sent1, sent2) for sent1 in data] for sent2 in data])\n",
    "    for i in range(N)\n",
    "    \n",
    "    nearest_index = np.unravel_index(np.argmin(dist), dist.shape)\n",
    "    print(dist)\n",
    "    print(nearest_index)\n",
    "\n",
    "all_pairs(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c90b13c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.28517894223366247\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "print(math.log(1.33) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cb9cba51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.2, 0.0, 0.0]\n",
      "0.3333333333333333\n",
      "[0.4, 0.0, 0.0]\n",
      "0.3333333333333333\n",
      "[0.0, 0.25, 0.25]\n",
      "0.6666666666666666\n",
      "[0.0, 0.25, 0.25]\n",
      "0.6666666666666666\n",
      "[0.2, 0.0, 0.25]\n",
      "0.6666666666666666\n",
      "[0.0, 0.25, 0.0]\n",
      "0.3333333333333333\n",
      "[0.0, 0.0, 0.25]\n",
      "0.3333333333333333\n",
      "[0.2, 0.25, 0.0]\n",
      "0.6666666666666666\n",
      "[-0.21972245773362198, -0.43944491546724396, -0.0, -0.0, -0.0810930216216329, -0.0, -0.0, -0.0810930216216329]\n",
      "[-0.21972245773362198, -0.43944491546724396, -0.0, -0.0, -0.0810930216216329, -0.0, -0.0, -0.0810930216216329]\n",
      "[-0.21972245773362198, -0.43944491546724396, -0.0, -0.0, -0.0810930216216329, -0.0, -0.0, -0.0810930216216329]\n"
     ]
    }
   ],
   "source": [
    "# DATA BLOCK\n",
    "\n",
    "text = '''he really really loves coffee\n",
    "my sister dislikes coffee\n",
    "my sister loves tea'''\n",
    "\n",
    "import math\n",
    "\n",
    "def main(text):\n",
    "    # split the text first into lines and then into lists of words\n",
    "    docs = [line.split() for line in text.splitlines()]\n",
    "\n",
    "    N = len(docs)\n",
    "\n",
    "    # create the vocabulary: the list of words that appear at least once\n",
    "    vocabulary = list(set(text.split()))\n",
    "\n",
    "    df = {}\n",
    "    tf = {}\n",
    "    for word in vocabulary:\n",
    "        # tf: number of occurrences of word w in document divided by document length\n",
    "        # note: tf[word] will be a list containing the tf of each word for each document\n",
    "        # for example tf['he'][0] contains the term frequence of the word 'he' in the first\n",
    "        # document\n",
    "        tf[word] = [doc.count(word)/len(doc) for doc in docs]\n",
    "        print(tf[word])\n",
    "        # df: number of documents containing word w\n",
    "        df[word] = sum([word in doc for doc in docs])/N\n",
    "        print(df[word])\n",
    "    # loop through documents to calculate the tf-idf values\n",
    "    for doc_index, doc in enumerate(docs):\n",
    "        tfidf = []\n",
    "        for word in vocabulary:\n",
    "            # ADD THE CORRECT FORMULA HERE. Remember to use the base 10 logarithm: math.log(x, 10)\n",
    "            tfidf.append(tf[word][0] * math.log(df[word])) \n",
    "\n",
    "        print(tfidf)\n",
    "\n",
    "main(text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d0861433",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.10034333188799371, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.10034333188799371, 0.0, 0.0, 0.0, 0.05017166594399686, 0.10034333188799371, 0.0, 0.0]]\n",
      "[[1000000.]]\n",
      "[[1000000.]]\n",
      "(0, 0)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "\n",
    "text = '''Humpty Dumpty sat on a wall\n",
    "Humpty Dumpty had a great fall\n",
    "all the king's horses and all the king's men\n",
    "couldn't put Humpty together again'''\n",
    "\n",
    "def find_tfidf(text):\n",
    "    # tasks your code should perform:\n",
    "    docs = [line.lower().split() for line in text.split('\\n')]\n",
    "    # 1. split the text into words, and get a list of unique words that appear in it\n",
    "    vocabulary = list(set(text.split()))\n",
    "    N = len(docs)\n",
    "    # a short one-liner to separate the text into sentences (with words lower-cased to make words equal \n",
    "    # despite casing) can be done with \n",
    "    # docs = [line.lower().split() for line in text.split('\\n')\n",
    "    # 2. go over each unique word and calculate its term frequency, and its document frequency\n",
    "    tf = {}\n",
    "    df = {}\n",
    "    for word in vocabulary:\n",
    "        tf[word] = [doc.count(word)/len(doc) for doc in docs]\n",
    "        df[word] = sum([word in doc for doc in docs])/N\n",
    "\n",
    "    # 3. after you have your term frequencies and document frequencies, go over each line in the text and \n",
    "    # calculate its TF-IDF representation, which will be a vector\n",
    "    tfidf_data = []\n",
    "    for doc_index, doc in enumerate(docs):\n",
    "        tfidf = []\n",
    "        for word in vocabulary:\n",
    "            if df[word] == 0:\n",
    "                df[word] = 1\n",
    "            tfidf.append(tf[word][doc_index] * math.log(1/df[word],10))\n",
    "        tfidf_data.append(tfidf)\n",
    "        print(tfidf_data)\n",
    "        return tfidf_data\n",
    "    # 4. after you have calculated the TF-IDF representations for each line in the text, you need to\n",
    "    # calculate the distances between each line to find which are the closest.\n",
    "def distance(row1,row2):\n",
    "    sum = 0\n",
    "    for m,n in zip(row1,row2):\n",
    "        sum = sum + (m-n)**2\n",
    "    return np.sqrt(sum)\n",
    "\n",
    "def find_nearest_pair(data):\n",
    "    N = len(data)\n",
    "    dist = np.empty((N,N),dtype = float)\n",
    "    print(dist)\n",
    "    for i in range(N):\n",
    "        for j in range(N):\n",
    "            if i == j:\n",
    "                dist[i][j] = 1000000\n",
    "            else:\n",
    "                dist[i][j] = distance(data[i],data[j])\n",
    "    print(dist)\n",
    "    print(np.unravel_index(np.argmin(dist),(N,N)))\n",
    "\n",
    "find_nearest_pair(find_tfidf(text))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "de620c06",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math, random        \t# just for generating random mountains                                 \t \n",
    "import numpy as np\n",
    "\n",
    "n = 10000 # size of the problem: number of possible solutions x = 0, ..., n-1\n",
    "\n",
    "def mountains(n):\n",
    "  h = [0]*n\n",
    "  for i in range(50):\n",
    "    c = random.randint(20, n-20)\n",
    "    w = random.randint(3, int(math.sqrt(n/5)))**2\n",
    "    s = random.random()\n",
    "    h[max(0, c-w):min(n, c+w)] = [h[i] + s*(w-abs(c-i)) for i in range(max(0, c-w), min(n, c+w))]\n",
    "\n",
    "    # scale the height so that the lowest point is 0.0 and the highest peak is 1.0\n",
    "  low = min(h)\n",
    "  high = max(h)\n",
    "  h = [y - low for y in h]\n",
    "  h = [y / (high-low) for y in h]\n",
    "  return h\n",
    "\n",
    "h = mountains(n)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b8781c7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
